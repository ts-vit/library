# Детальная выжимка по главам: AI-инженерия (Чип Хьюен)

Фундаментальный труд Чип Хьюен (2025) о том, как строить реальные продукты на базе LLM. Книга переводит фокус с обучения моделей на их эффективное применение.

---

### Глава 1. Расцвет AI-инженерии
*   **Новая дисциплина:** AI-инженер не обучает веса модели, он проектирует системы вокруг них.
*   **Смена фокуса:** От сбора датасетов к управлению контекстом и промптами.
*   **Цикл разработки:** Почему итерации в AI-инженерии в 10 раз быстрее, чем в классическом ML.

### Глава 2. Стек современных ИИ-приложений
*   **Foundation Models:** Выбор между проприетарными (OpenAI, Anthropic) и открытыми (Llama, Mistral) моделями.
*   **Vector DB:** Роль векторных баз данных как долговременной памяти систем.
*   **Инфраструктура:** Почему задержка (Latency) и стоимость (Cost) становятся главными инженерными вызовами.

### Глава 3. Промпт-инжиниринг как проектирование
*   **Техники:** Few-shot, Chain-of-Thought, ReAct.
*   **Программируемые промпты:** Использование шаблонизаторов и динамическая сборка промпта на основе данных пользователя.
*   **Безопасность:** Защита от Jailbreak и внедрения инструкций через данные (Prompt Injection).

### Глава 4. Оценка (Evaluation) — Самая сложная часть
*   **Проблема:** Как понять, что "стало лучше", если ответы модели недетерминированы?
*   **Методы оценки:** 
    *   *Unit-тесты для ИИ:* Ожидаемые ключевые слова или форматы.
    *   *LLM-as-a-judge:* Использование сильной модели для оценки слабой.
    *   *Человеческая оценка:* Почему она все еще важна, но не масштабируется.
*   **Benchmark:** Создание собственных наборов тестов под конкретную бизнес-задачу.

### Глава 5. RAG: Retrieval Augmented Generation
*   **Зачем нужен RAG:** Преодоление ограничений по дате знаний и конфиденциальности.
*   **Пайплайн:** Загрузка -> Чанкинг -> Эмбеддинги -> Поиск -> Генерация.
*   **Оптимизация:** Как выбор размера чанка и перекрытие (overlap) влияют на точность.
*   **Продвинутый RAG:** Гибридный поиск, переранжирование (Re-ranking) и расширение запросов.

### Глава 6. Fine-tuning: Когда он действительно нужен
*   **RAG vs FT:** RAG для знаний, Fine-tuning для стиля, формата или специфического домена (например, медицина/право).
*   **Методы:** LoRA и QLoRA — как дообучать огромные модели на обычном GPU.
*   **Подготовка данных:** Почему качество данных важнее их количества в 100 раз.

### Глава 7. Агенты и Использование Инструментов
*   **От чата к действию:** Обучение модели вызывать функции (Function Calling).
*   **Планирование:** Как научить ИИ разбивать сложные задачи на шаги.
*   **Циклы:** Проверка результата действия и повторная попытка при ошибке.

### Глава 8. Оптимизация и Деплой (Production)
*   **Latency:** Техники ускорения (Квантование, Спекулятивное декодирование).
*   **Стоимость:** Как экономить токены через кеширование и выбор более дешевых моделей для простых подзадач.
*   **Мониторинг:** Отслеживание галлюцинаций и дрейфа качества ответов в реальном времени.

### Глава 9. Будущее AI-инженерии
*   **Мультимодальность:** Видео, аудио и изображения в одном пайплайне.
*   **Персонализация:** Агенты, которые учатся на каждом клике пользователя.
*   **Этика и ответственность:** Как строить системы, которые не причиняют вред.

---
**Связь с проектом Toshik:** Эта книга — технический план для `toshik-babe`. Особенно главы про Оценку (Eval) и RAG, которые мы сейчас внедряем.
